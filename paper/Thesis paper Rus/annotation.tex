\newpage


\begin{abstract}
В данной работе исследуется метод уменьшения размерности пространства обучаемых параметров в задаче детектирования AI текстов, задача многоклассовой классификации. Для дообучения использовалась дистилированная модель трансформер с двунаправленным кодированием представлений~(англ. DistilRoBERTa) с использованием низкорангового разложения~(англ. Low Rank Adaptation) матриц весов. Были проведены эксперименты для оценки эффективности использования LoRA адаптера для аппроксимации матрицы весов с точки зрения времени, ресурсов или точности. Было показано, что при меньших ресурсах модель DistilRoBERTa с LoRA адаптером может получить те же показатели метрик  для классификации текстов, написанных человеком, что и DistilRoBERTa без LoRA на наборе данных с 4 классами.


\smallskip
\textbf{Ключевые слова}:  машинное обучение; линейная алгебра; аппроксимация матриц; уменьшение размерности пространств; классификация AI текстов; многоклассовая классификация текстов; большие языковые модели.
\end{abstract}