@article{wold1987principal,
  title={Principal component analysis},
  author={Wold, Svante and Esbensen, Kim and Geladi, Paul},
  journal={Chemometrics and intelligent laboratory systems},
  volume={2},
  number={1-3},
  pages={37--52},
  year={1987},
  publisher={Elsevier}
}

@inproceedings{sun2019fine,
  title={How to fine-tune bert for text classification?},
  author={Sun, Chi and Qiu, Xipeng and Xu, Yige and Huang, Xuanjing},
  booktitle={Chinese computational linguistics: 18th China national conference, CCL 2019, Kunming, China, October 18--20, 2019, proceedings 18},
  pages={194--206},
  year={2019},
  organization={Springer}
}

@article{qazi2024gpt,
  title={GPT-generated Text Detection: Benchmark Dataset and Tensor-based Detection Method},
  author={Qazi, Zubair and Shiao, William and Papalexakis, Evangelos E},
  journal={arXiv preprint arXiv:2403.07321},
  year={2024}
}

@article{fonti2017feature,
  title={Feature selection using lasso},
  author={Fonti, Valeria and Belitser, Eduard},
  journal={VU Amsterdam research paper in business analytics},
  volume={30},
  pages={1--25},
  year={2017},
  publisher={Business Analytics Master Amsterdam, The Netherland}
}

@inproceedings{zhai2018chi,
  title={A chi-square statistics based feature selection method in text classification},
  author={Zhai, Yujia and Song, Wei and Liu, Xianjun and Liu, Lizhen and Zhao, Xinlei},
  booktitle={2018 IEEE 9th International conference on software engineering and service science (ICSESS)},
  pages={160--163},
  year={2018},
  organization={IEEE}
}

@article{gu2012generalized,
  title={Generalized fisher score for feature selection},
  author={Gu, Quanquan and Li, Zhenhui and Han, Jiawei},
  journal={arXiv preprint arXiv:1202.3725},
  year={2012}
}

 @article{oseledets2011tensor,
  title={Tensor-train decomposition},
  author={Oseledets, Ivan V},
  journal={SIAM Journal on Scientific Computing},
  volume={33},
  number={5},
  pages={2295--2317},
  year={2011},
  publisher={SIAM}
}

@article{zare2018extension,
  title={Extension of PCA to higher order data structures: An introduction to tensors, tensor decompositions, and tensor PCA},
  author={Zare, Ali and Ozdemir, Alp and Iwen, Mark A and Aviyente, Selin},
  journal={Proceedings of the IEEE},
  volume={106},
  number={8},
  pages={1341--1358},
  year={2018},
  publisher={IEEE}
}

@article{hsieh2023distilling,
  title={Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes},
  author={Hsieh, Cheng-Yu and Li, Chun-Liang and Yeh, Chih-Kuan and Nakhost, Hootan and Fujii, Yasuhisa and Ratner, Alexander and Krishna, Ranjay and Lee, Chen-Yu and Pfister, Tomas},
  journal={arXiv preprint arXiv:2305.02301},
  year={2023}
}

@misc{hinton2015nips,
  title={NIPS Deep Learning and Representation Learning Workshop},
  author={Hinton, G and Vinyals, O and Dean, J},
  year={2015}
}

@article{vapnik2015learning,
  title={Learning using privileged information: similarity control and knowledge transfer.},
  author={Vapnik, Vladimir and Izmailov, Rauf and others},
  journal={J. Mach. Learn. Res.},
  volume={16},
  number={1},
  pages={2023--2049},
  year={2015}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{he2023mgtbench,
  title={Mgtbench: Benchmarking machine-generated text detection},
  author={He, Xinlei and Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Zhang, Yang},
  journal={arXiv preprint arXiv:2303.14822},
  year={2023}
}

@article{dettmers2024qlora,
  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{liang2023gpt,
  title={GPT detectors are biased against non-native English writers},
  author={Liang, Weixin and Yuksekgonul, Mert and Mao, Yining and Wu, Eric and Zou, James},
  journal={Patterns},
  volume={4},
  number={7},
  year={2023},
  publisher={Elsevier}
}

@article{yang2023dna,
  title={Dna-gpt: Divergent n-gram analysis for training-free detection of gpt-generated text},
  author={Yang, Xianjun and Cheng, Wei and Petzold, Linda and Wang, William Yang and Chen, Haifeng},
  journal={arXiv preprint arXiv:2305.17359},
  year={2023}
}

@article{aghajanyan2020intrinsic,
  title={Intrinsic dimensionality explains the effectiveness of language model fine-tuning},
  author={Aghajanyan, Armen and Zettlemoyer, Luke and Gupta, Sonal},
  journal={arXiv preprint arXiv:2012.13255},
  year={2020}
}

@article{li2018measuring,
  title={Measuring the intrinsic dimension of objective landscapes},
  author={Li, Chunyuan and Farkhoor, Heerad and Liu, Rosanne and Yosinski, Jason},
  journal={arXiv preprint arXiv:1804.08838},
  year={2018}
}

@article{thickstun2021transformer,
  title={The transformer model in equations},
  author={Thickstun, John},
  journal={University of Washington: Seattle, WA, USA},
  year={2021}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{lee2023mathematical,
  title={A mathematical investigation of hallucination and creativity in gpt models},
  author={Lee, Minhyeok},
  journal={Mathematics},
  volume={11},
  number={10},
  pages={2320},
  year={2023},
  publisher={MDPI}
}

@article{abdali2024decoding,
  title={Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text},
  author={Abdali, Sara and Anarfi, Richard and Barberan, CJ and He, Jia},
  journal={arXiv preprint arXiv:2403.05750},
  year={2024}
}

@article{qasim2022fine,
  title={A fine-tuned BERT-based transfer learning approach for text classification},
  author={Qasim, Rukhma and Bangyal, Waqas Haider and Alqarni, Mohammed A and Almazroi, Abdulwahab Ali},
  journal={Journal of healthcare engineering},
  volume={2022},
  year={2022},
  publisher={Hindawi Limited}
}

@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}

@article{dai2024instructblip,
  title={Instructblip: Towards general-purpose vision-language models with instruction tuning},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale N and Hoi, Steven},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{yu2023gpt,
  title={Gpt paternity test: Gpt generated text detection with gpt genetic inheritance},
  author={Yu, Xiao and Qi, Yuang and Chen, Kejiang and Chen, Guoqiang and Yang, Xi and Zhu, Pengyuan and Zhang, Weiming and Yu, Nenghai},
  journal={arXiv preprint arXiv:2305.12519},
  year={2023}
}

@inproceedings{semeval2024task8,
  author    = {Wang, Yuxia  and  Mansurov, Jonibek  and  Ivanov, Petar  and  su, jinyan  and  Shelmanov, Artem  and  Tsvigun, Akim  and  Mohammed Afzal, Osama  and  Mahmoud, Tarek  and  Puccetti, Giovanni  and  Arnold, Thomas  and  Whitehouse, Chenxi  and  Aji, Alham Fikri  and  Habash, Nizar  and  Gurevych, Iryna  and  Nakov, Preslav},
  title     = {SemEval-2024 Task 8: Multidomain, Multimodel and Multilingual Machine-Generated Text Detection},
  booktitle      = {Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)},
  month          = {June},
  year           = {2024},
  address        = {Mexico City, Mexico},
  publisher      = {Association for Computational Linguistics},
  pages     = {2041--2063},
  abstract  = {We present the results and the main findings of SemEval-2024 Task 8: Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection. The task featured three subtasks. Subtask A is a binary classification task determining whether a text is written by a human or generated by a machine. This subtask has two tracks: a monolingual track focused solely on English texts and a multilingual track. Subtask B is to detect the exact source of a text, discerning whether it is written by a human or generated by a specific LLM. Subtask C aims to identify the changing point within a text, at which the authorship transitions from human to machine. The task attracted a large number of participants: subtask A monolingual (126), subtask A multilingual (59), subtask B (70), and subtask C (30). In this paper, we present the task, analyze the results, and discuss the system submissions and the methods they used. For all subtasks, the best systems used LLMs.},
  url       = {https://aclanthology.org/2024.semeval2024-1.275}
}